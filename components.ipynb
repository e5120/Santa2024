{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e79be5-ed69-4257-90b5-2c467fc3ac96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 6, 7, 8, 4, 5, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Operator(metaclass=ABCMeta):\n",
    "    def __call__(self, tokens):\n",
    "        if isinstance(tokens, (np.ndarray, torch.Tensor)):\n",
    "            tokens = tokens.tolist()\n",
    "        return self.apply(tokens)\n",
    "\n",
    "    @abstractmethod\n",
    "    def apply(self, tokens):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class OnePointShuffle(Operator):\n",
    "    def apply(self, tokens):\n",
    "        i = random.choice(np.arange(1, len(tokens)))\n",
    "        tokens = tokens[i:] + tokens[:i]\n",
    "        return tokens\n",
    "\n",
    "\n",
    "class PairPointShuffle(Operator):\n",
    "    def apply(self, tokens):\n",
    "        i, j = random.sample(range(len(tokens)), k=2)\n",
    "        tokens[i], tokens[j] = tokens[j], tokens[i]\n",
    "        return tokens\n",
    "\n",
    "\n",
    "class TokensShuffle(Operator):\n",
    "    def __init__(self, min_tokens=1, max_tokens=3):\n",
    "        assert min_tokens < max_tokens\n",
    "        self.min_tokens = min_tokens\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def apply(self, tokens):\n",
    "        assert len(tokens) > self.max_tokens\n",
    "        while True:\n",
    "            i, j = random.sample(range(len(tokens)), k=2)\n",
    "            if i > j:\n",
    "                i, j = j, i\n",
    "            i_end = i + random.randint(self.min_tokens, self.max_tokens+1)\n",
    "            j_end = j + random.randint(self.min_tokens, self.max_tokens+1)\n",
    "            if i_end <= j:\n",
    "                break\n",
    "        tokens = tokens[:i] + tokens[j: j_end] + tokens[i_end: j] + tokens[i: i_end] + tokens[j_end:]\n",
    "        return tokens\n",
    "\n",
    "\n",
    "class TokensReverse(Operator):\n",
    "    def __init__(self, min_tokens=2, max_tokens=3):\n",
    "        assert min_tokens < max_tokens\n",
    "        self.min_tokens = min_tokens\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def apply(self, tokens):\n",
    "        assert len(tokens) > self.max_tokens\n",
    "        i = random.choice(range(len(tokens)-1))\n",
    "        j = random.choice(range(self.min_tokens, self.max_tokens+1))\n",
    "        k = min(i+j, len(tokens))\n",
    "        tokens[i:k] = tokens[i:k][::-1]\n",
    "        return tokens\n",
    "\n",
    "\n",
    "class TokensInsert(Operator):\n",
    "    def __init__(self, min_tokens=2, max_tokens=3):\n",
    "        assert min_tokens < max_tokens\n",
    "        self.min_tokens = min_tokens\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def apply(self, tokens):\n",
    "        assert len(tokens) > self.max_tokens\n",
    "        i = random.choice(range(len(tokens)))\n",
    "        j = random.choice(range(self.min_tokens, self.max_tokens+1))\n",
    "        k = min(i+j, len(tokens))\n",
    "        sub_tokens = tokens[i:k]\n",
    "        main_tokens = tokens[:i] + tokens[k:]\n",
    "        l = random.choice(range(len(main_tokens)))\n",
    "        tokens = main_tokens[:l] + sub_tokens + main_tokens[l:]\n",
    "        return tokens\n",
    "\n",
    "\n",
    "tokens = list(range(10))\n",
    "op = TokensInsert()\n",
    "op(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17235399-7340-4187-b152-c82178fc30cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({\"<class '__main__.TokensInsert'>\": 3376,\n",
       "         \"<class '__main__.TokensShuffle'>\": 3320,\n",
       "         \"<class '__main__.TokensReverse'>\": 3304})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "class BaseSampler(metaclass=ABCMeta):\n",
    "    def __init__(self, ops):\n",
    "        self.ops = ops\n",
    "        self.indices = list(range(len(ops)))\n",
    "        self.index = -1\n",
    "        self.weight = np.ones(len(ops))\n",
    "\n",
    "    def sample(self):\n",
    "        self.index = np.random.choice(self.indices, p=self.weight/self.weight.sum())\n",
    "        return self.ops[self.index]\n",
    "        \n",
    "    @abstractmethod\n",
    "    def update(self, diff):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class UniformSampler(BaseSampler):\n",
    "    def __init__(self, ops):\n",
    "        super().__init__(ops)\n",
    "\n",
    "    def update(self, diff):\n",
    "        return\n",
    "\n",
    "\n",
    "ops = [TokensInsert(), TokensReverse(), TokensShuffle()]\n",
    "from collections import Counter\n",
    "sampler = UniformSampler(ops)\n",
    "counter = Counter()\n",
    "for _ in range(10000):\n",
    "    op = sampler.sample()\n",
    "    counter[str(op.__class__)] += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d0ad58-ec21-41cc-9302-e2ee8b35c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14426930215331735"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Scorer:\n",
    "    def __init__(self, mi=0, ma=1):\n",
    "        self.mi = mi\n",
    "        self.ma = ma\n",
    "    def get_perplexity(self, text, batch_size=32):\n",
    "        return random.uniform(self.mi, self.ma)\n",
    "\n",
    "\n",
    "scorer = Scorer()\n",
    "scorer.get_perplexity(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5abb169f-2837-46d5-9ade-413d052316f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "# ToDo: どの操作がスコアを上げたのかをログする機能の追加\n",
    "def simulated_annealing(text, sampler, scorer, temp_start=10, temp_end=0.5, cooling_rate=0.95, steps_per_temp=5, alpha=1.0, precomputed={}, verbose=False, logging_step=1, batch_size=1):\n",
    "    # initial setting\n",
    "    text = text.strip()\n",
    "    tokens = text.split(\" \")\n",
    "    best_tokens = tokens.copy()\n",
    "    best_score = scorer.get_perplexity(text, batch_size=batch_size)\n",
    "    # optimization\n",
    "    temp = temp_start\n",
    "    print(f\"start temp: {temp:.2f}, init score: {best_score:.5f}\")\n",
    "    num_steps = 0\n",
    "    while temp > temp_end:\n",
    "        num_steps += 1\n",
    "        for _ in range(steps_per_temp):\n",
    "            op = sampler.sample()\n",
    "            tokens = op(tokens)\n",
    "            new_text = \" \".join(tokens)\n",
    "            if new_text in precomputed:\n",
    "                new_score = precomputed[new_text]\n",
    "            else:\n",
    "                new_score = scorer.get_perplexity(new_text, batch_size=batch_size)\n",
    "                precomputed[new_text] = new_score\n",
    "            delta = new_score - best_score\n",
    "            sampler.update(-delta)\n",
    "            if delta < 0:\n",
    "                # improvement\n",
    "                best_tokens = tokens.copy()\n",
    "                best_score = new_score\n",
    "                print(\">\", end=\"\")\n",
    "            elif random.random() < math.exp(-alpha*delta / temp):\n",
    "                # explore\n",
    "                print(\"<\", end=\"\")\n",
    "            else:\n",
    "                # exploit\n",
    "                tokens = best_tokens.copy()\n",
    "                print(\"-\", end=\"\")\n",
    "        temp *= cooling_rate\n",
    "        if verbose and num_steps % logging_step == 0:\n",
    "            print(f\"\\ncurrent temp: {temp:.2f}, current score: {best_score:.5f}\")\n",
    "    return \" \".join(best_tokens), best_score, precomputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b961910-04f6-40bd-990e-d277b9297d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_permutations(tokens, fixed_ids=[]):\n",
    "    tokens = np.array(tokens)\n",
    "    fixed_ids = np.array(sorted(fixed_ids))\n",
    "    mutable_tokens = np.array([\n",
    "        tokens[i] for i in range(len(tokens)) if i not in fixed_ids\n",
    "    ])\n",
    "    assert len(mutable_tokens) < 11\n",
    "    perms = list(map(list, itertools.permutations(mutable_tokens)))\n",
    "    for perm in perms:\n",
    "        for i in fixed_ids:\n",
    "            perm.insert(i, tokens[i])\n",
    "    return perms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dab199-1494-457e-8768-eeb669a4a1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
